{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T15:30:12.693649Z",
     "start_time": "2025-05-23T15:30:12.561427Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "# --------------------------------------\n",
    "# 1. Training data (X = inputs, Y = outputs)\n",
    "# --------------------------------------\n",
    "# Example: Predicting house prices\n",
    "# Features: [Size in sq ft, Number of bedrooms]\n",
    "X = np.array([\n",
    "    [2104, 3],\n",
    "    [1600, 2],\n",
    "    [2400, 4],\n",
    "    [1416, 2],\n",
    "    [3000, 4]\n",
    "], dtype=float)\n",
    "\n",
    "# Target: Price in $1000s\n",
    "Y = np.array([399.9, 329.9, 369.0, 232.0, 539.9], dtype=float)\n",
    "\n",
    "# Number of training examples and features\n",
    "m = X.shape[0]  # number of rows\n",
    "n = X.shape[1]  # number of features\n",
    "\n",
    "# --------------------------------------\n",
    "# 2. Feature Scaling (normalize each column)\n",
    "# --------------------------------------\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std  # Z = (X - mean) / std\n",
    "\n",
    "# --------------------------------------\n",
    "# 3. Initialize weights and bias\n",
    "# --------------------------------------\n",
    "W = np.zeros(n)  # weights for features\n",
    "B = 0            # bias (intercept)\n",
    "\n",
    "# --------------------------------------\n",
    "# 4. Define the cost function (Mean Squared Error)\n",
    "# Formula: Cost = (1/2m) * Σ((prediction - actual)^2)\n",
    "# --------------------------------------\n",
    "def compute_cost(X, Y, W, B):\n",
    "    m = len(Y)\n",
    "    predictions = X @ W + B\n",
    "    errors = predictions - Y\n",
    "    cost = (1 / (2 * m)) * np.sum(errors ** 2)\n",
    "    return cost\n",
    "\n",
    "# --------------------------------------\n",
    "# 5. Compute gradients\n",
    "# Formula:\n",
    "#   dW = (1/m) * Σ((prediction - actual) * x)\n",
    "#   dB = (1/m) * Σ((prediction - actual))\n",
    "# --------------------------------------\n",
    "def compute_gradients(X, Y, W, B):\n",
    "    m = len(Y)\n",
    "    predictions = X @ W + B\n",
    "    errors = predictions - Y\n",
    "    dW = (1 / m) * (X.T @ errors)\n",
    "    dB = (1 / m) * np.sum(errors)\n",
    "    return dW, dB\n",
    "\n",
    "# --------------------------------------\n",
    "# 6. Gradient Descent Algorithm\n",
    "# --------------------------------------\n",
    "def gradient_descent(X, Y, W, B, learning_rate, iterations):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        dW, dB = compute_gradients(X, Y, W, B)\n",
    "\n",
    "        # Update step:\n",
    "        # W = W - α * dW\n",
    "        # B = B - α * dB\n",
    "        W = W - learning_rate * dW\n",
    "        B = B - learning_rate * dB\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            cost = compute_cost(X, Y, W, B)\n",
    "            cost_history.append(cost)\n",
    "            print(f\"Iteration {i:4d} | Cost: {cost:.2f}\")\n",
    "\n",
    "    return W, B, cost_history\n",
    "\n",
    "# --------------------------------------\n",
    "# 7. Run Gradient Descent\n",
    "# --------------------------------------\n",
    "learning_rate = 0.1\n",
    "iterations = 1000\n",
    "W_final, B_final, cost_history = gradient_descent(X, Y, W, B, learning_rate, iterations)\n",
    "\n",
    "# --------------------------------------\n",
    "# 8. Show final parameters\n",
    "# --------------------------------------\n",
    "print(\"\\nFinal weights (W):\", W_final)\n",
    "print(\"Final bias (B):\", B_final)\n",
    "\n",
    "# --------------------------------------\n",
    "# 9. Make predictions\n",
    "# --------------------------------------\n",
    "print(\"\\nPredictions vs Actual:\")\n",
    "for i in range(m):\n",
    "    prediction = X[i] @ W_final + B_final\n",
    "    print(f\"Prediction: {prediction:.2f} | Actual: {Y[i]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 | Cost: 60383.47\n",
      "Iteration  100 | Cost: 474.04\n",
      "Iteration  200 | Cost: 261.57\n",
      "Iteration  300 | Cost: 201.35\n",
      "Iteration  400 | Cost: 184.28\n",
      "Iteration  500 | Cost: 179.44\n",
      "Iteration  600 | Cost: 178.07\n",
      "Iteration  700 | Cost: 177.68\n",
      "Iteration  800 | Cost: 177.57\n",
      "Iteration  900 | Cost: 177.54\n",
      "\n",
      "Final weights (W): [173.87055345 -85.33847914]\n",
      "Final bias (B): 374.13999999999976\n",
      "\n",
      "Predictions vs Actual:\n",
      "Prediction: 374.14 | Actual: 399.9\n",
      "Prediction: 315.49 | Actual: 329.9\n",
      "Prediction: 369.21 | Actual: 369.0\n",
      "Prediction: 259.25 | Actual: 232.0\n",
      "Prediction: 552.61 | Actual: 539.9\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6159cf1871ec117a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
